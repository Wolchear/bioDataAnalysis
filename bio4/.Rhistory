###### Distance Weighted Discrimination (Papildoma)
model_dwd <- krr(smoking ~ ., data = train_transposed, kernel = "vanilladot")
library(e1071)
library(kernlab)
### Random Forest Classification ##############################################
set.seed(123)
###### Distance Weighted Discrimination (Papildoma)
model_dwd <- krr(smoking ~ ., data = train_transposed, kernel = "vanilladot")
###### Distance Weighted Discrimination (Papildoma)
model_dwd <- kda(smoking ~ ., data = train_transposed)
###### Distance Weighted Discrimination (Papildoma)
model_logistic <- glm(smoking ~ ., data = train_transposed, family = "binomial")
# Предсказание классов для тестовых данных
pr_logistic <- predict(model_logistic, test_transposed, type = "response") >= 0.5
# Вывод матрицы ошибок
confusionMatrix(pr_logistic, test_transposed$smoking)
###### Distance Weighted Discrimination (Papildoma)
model_logistic <- glm(smoking ~ ., data = train_transposed, family = "binomial", control = list(maxit = 100))
print(summary(model_logistic))
pr_logistic <- predict(model_logistic, test_transposed, type = "response") >= 0.5
View(model_logistic)
install.packages("glmnet")
library(glmnet)
###### Distance Weighted Discrimination (Papildoma)
x_train <- as.matrix(train_transposed[,-ncol(train_transposed)])
y_train <- as.numeric(train_transposed$smoking) - 1  # Преобразование к числовому формату: 0 для non-smoker, 1 для smoker
lasso_model <- glmnet(x_train, y_train, alpha = 1, family = "binomial")
print(lasso_model)
x_test <- as.matrix(test_transposed[,-ncol(test_transposed)])
pr_lasso <- predict(lasso_model, newx = x_test, s = "lambda.min", type = "response")
View(x_train)
pr_lasso <- predict(lasso_model, newx = x_test, type = "response")
pr_lasso_binary <- ifelse(pr_lasso >= 0.5, 1, 0)
confusionMatrix(pr_lasso_binary, test_transposed$smoking)
pr_lasso_binary <- ifelse(pr_lasso >= 0.5, 1, 0)
confusionMatrix(pr_lasso_binary, test_transposed$smoking)
unique(x_tes$smoking)
unique(x_test$smoking)
unique(x_test)
confusionMatrix(pr_lasso_binary, as.numeric(test_transposed$smoking))
data <- readRDS("data2.rds")
genomemap <- readRDS("genomemap2.rds")
samplekey <- readRDS("samplekey2.rds")
library(randomForest)
library(datasets)
library(caret)
### Random Forest Classification ##############################################
set.seed(123)
samplekey_tcd4 <- samplekey[samplekey$celltype == "tcd4",]
data_tcd4 <- data[,rownames(samplekey_tcd4)]
data_tcd4_variable <- data[order(apply(data, 1, sd),
decreasing = TRUE),][1:1000, ]
ind <- sample(2, ncol(data_tcd4_variable), replace = TRUE, prob = c(0.8, 0.2))
train <- data_tcd4_variable[,ind==1]
test <- data_tcd4_variable[,ind==2]
train_transposed <- as.data.frame(t(train))
train_donors <- row.names(train_transposed)
train_transposed$smoking <- samplekey[train_donors,]$smoking
train_transposed$smoking <- as.factor(train_transposed$smoking)
model_rf <- randomForest(smoking ~ ., data = train_transposed, proximity=TRUE)
print(model_rf)
test_transposed <- as.data.frame(t(test))
test_donors <- row.names(test_transposed)
test_transposed$smoking <- samplekey[test_donors,]$smoking
test_transposed$smoking <- as.factor(test_transposed$smoking)
pr <- predict(model_rf, test_transposed)
confusionMatrix(pr, test_transposed$ smoking)
### Validation #################################################################
train_control <- trainControl(method = "cv", number = 10)
### Principine komponente ######################################################
pca_result <- prcomp(train_transposed[,-ncol(train_transposed)], scale = TRUE)
summary(pca_result)
selected_components <- predict(pca_result, newdata = train_transposed)[, 1:5]
model_rf_with_pca <- randomForest(smoking ~ ., data = train_transposed_with_pca, proximity = TRUE)
train_transposed_with_pca <- cbind(train_transposed, selected_components)
model_rf_with_pca <- randomForest(smoking ~ ., data = train_transposed_with_pca, proximity = TRUE)
predict(model_rf_with_pca, newdata = test_transposed)
train_control <- trainControl(method = "cv", number = 10)
classification_model_with_pca <- train(smoking ~ ., data = train_transposed_with_pca,
method = "rf", trControl = train_control)
print(classification_model_with_pca)
pr_class <- predict(classification_model_with_pca, newdata = test_transposed)
selected_components_test <- predict(pca_result_train, newdata = test_transposed)[, 1:5]
selected_components_test <- predict(pca_result, newdata = test_transposed)[, 1:5]
View(train_transposed)
selected_components_test <- predict(pca_result, newdata = test_transposed)[, 1:5]
train_transposed_with_pca <- cbind(test_transposed, selected_components_test)
pr_class <- predict(classification_model_with_pca, newdata = test_transposed)
pr_class <- predict(classification_model_with_pca, newdata = train_transposed_with_pca)
print(pr_class)
pr_component <- predict(classification_model_with_pca, newdata = train_transposed_with_pca)
confusionMatrix(pr_component, test_transposed$smoking)
### Principine komponente ######################################################
pc <- prcomp(train_transposed[,-5],
center = TRUE,
scale. = TRUE)
grep("smoking", column_names)
grep("smoking", colnames(train_transposed))
### Principine komponente ######################################################
pc <- prcomp(training[,-1001],
center = TRUE,
scale. = TRUE)
### Principine komponente ######################################################
pc <- prcomp(train_transposed[,-1001],
center = TRUE,
scale. = TRUE)
attributes(pc)
pc$center
print(pc)
### Principine komponente ######################################################
pc <- prcomp(train_transposed[,-5],
center = TRUE,
scale. = TRUE)
### Principine komponente ######################################################
pc <- prcomp(train_transposed[,-1001],
center = TRUE,
scale. = TRUE)
summary(pc)
### Principine komponente ######################################################
pc <- prcomp(train_transposed[,-1001],
center = TRUE,
scale. = TRUE,
n.comp = 100)
trg <- predict(pc, train_transposed)
tst <- predict(pc, testing)
tst <- predict(pc, test_transposed)
mymodel <- multinom(Species~PC1+PC2+PC3+PC5, data = trg)
library(nnet)
mymodel <- multinom(Species~PC1+PC2+PC3+PC5, data = trg)
trg <- data.frame(trg, train_transposed[1001])
tst <- predict(pc, test_transposed)
mymodel <- multinom(Species~PC1+PC2+PC3+PC5, data = trg)
mymodel <- multinom(smoking~PC1+PC2+PC3+PC5, data = trg)
tst <- data.frame(tst, test_transposed[1001]
summary(mymodel)
trg <- predict(pc, train_transposed)
trg <- data.frame(trg, train_transposed[1001])
tst <- predict(pc, test_transposed)
tst <- data.frame(tst, test_transposed[1001]
summary(mymodel)
tst <- data.frame(tst, test_transposed[1001])
tst <- predict(pc, test_transposed)
tst <- data.frame(tst, test_transposed[1001])
mymodel <- multinom(smoking~PC1+PC2+PC3+PC5, data = trg)
summary(mymodel)
p <- predict(mymodel, trg)
table(p, trg$Species)
table(p, trg$smoking)
p1 <- predict(mymodel, tst)
table(p1, tst$smoking
table(p1, tst$smoking)
table(p1, tst$smoking)
mymodel <- multinom(smoking~PC1+PC2+PC3, data = trg)
p <- predict(mymodel, trg)
table(p, trg$smoking)
p1 <- predict(mymodel, tst)
table(p1, tst$smoking)
mymodel <- multinom(smoking~PC1+PC2+PC3+P4+PC5+PC6, data = trg)
mymodel <- multinom(smoking~PC1+PC2+PC3+PC4+PC5+PC6, data = trg)
p <- predict(mymodel, trg)
table(p, trg$smoking)
p1 <- predict(mymodel, tst)
mymodel <- multinom(smoking~, data = trg)
mymodel <- multinom(smoking~., data = trg)
p <- predict(mymodel, trg)
table(p, trg$smoking)
p1 <- predict(mymodel, tst)
table(p1, tst$smoking)
confusionMatrix(p1, tst$smoking)
p <- predict(mymodel, trg)
confusionMatrix(p, trg$smoking)
confusionMatrix(p1, tst$smoking)
# Train and evaluate SVM
model_svm <- train(smoking ~ ., data = train_transposed,
method = "svmRadial", trControl = train_control)
svm_results <- evaluate_classifier(model_svm,
test_transposed, test_transposed$smoking)
library(e1071)  # For SVM
library(class)  # For KNN
library(gbm)    # For GBM
library(MASS)   # For LDA
svm_results <- evaluate_classifier(model_svm,
test_transposed, test_transposed$smoking)
####################
# Function to evaluate classifiers
evaluate_classifier <- function(model, test_data, test_labels) {
predictions <- predict(model, newdata = test_data)
conf_matrix <- confusionMatrix(predictions, test_labels)
return(list(predictions = predictions, confusion_matrix = conf_matrix))
}
svm_results <- evaluate_classifier(model_svm,
test_transposed, test_transposed$smoking)
# Train and evaluate KNN
model_knn <- train(smoking ~ ., data = train_transposed, method = "knn",
trControl = train_control, tuneLength = 10)
knn_results <- evaluate_classifier(model_knn,
test_transposed, test_transposed$smoking)
# Train and evaluate GBM
model_gbm <- train(smoking ~ ., data = train_transposed, method = "gbm",
trControl = train_control, verbose = FALSE)
library(e1071)  # For SVM
library(class)  # For KNN
library(gbm)    # For GBM
library(MASS)   # For LDA
### Random Forest Classification ##############################################
set.seed(123)
install.packages('gbm')
library(gbm)    # For GBM
####################
# Function to evaluate classifiers
evaluate_classifier <- function(model, test_data, test_labels) {
predictions <- predict(model, newdata = test_data)
conf_matrix <- confusionMatrix(predictions, test_labels)
return(list(predictions = predictions, confusion_matrix = conf_matrix))
}
# Train and evaluate Random Forest
model_rf <- train(smoking ~ ., data = train_transposed,
method = "rf", trControl = train_control)
rf_results <- evaluate_classifier(model_rf,
test_transposed, test_transposed$smoking)
# Train and evaluate SVM
model_svm <- train(smoking ~ ., data = train_transposed,
method = "svmRadial", trControl = train_control)
svm_results <- evaluate_classifier(model_svm,
test_transposed, test_transposed$smoking)
# Train and evaluate KNN
model_knn <- train(smoking ~ ., data = train_transposed, method = "knn",
trControl = train_control, tuneLength = 10)
knn_results <- evaluate_classifier(model_knn,
test_transposed, test_transposed$smoking)
# Train and evaluate GBM
model_gbm <- train(smoking ~ ., data = train_transposed, method = "gbm",
trControl = train_control, verbose = FALSE)
gbm_results <- evaluate_classifier(model_gbm,
test_transposed, test_transposed$smoking)
# Train and evaluate Logistic Regression
model_glm <- train(smoking ~ ., data = train_transposed, method = "glm",
family = binomial, trControl = train_control)
glm_results <- evaluate_classifier(model_glm, test_transposed,
test_transposed$smoking)
# Train and evaluate Linear Discriminant Analysis (LDA)
model_lda <- train(smoking ~ ., data = train_transposed,
method = "lda", trControl = train_control)
lda_results <- evaluate_classifier(model_lda,
test_transposed, test_transposed$smoking)
results <- data.frame(
Model = c("Random Forest", "SVM", "KNN", "GBM", "Logistic Regression", "LDA"),
Accuracy = c(rf_results$confusion_matrix$overall['Accuracy'],
svm_results$confusion_matrix$overall['Accuracy'],
knn_results$confusion_matrix$overall['Accuracy'],
gbm_results$confusion_matrix$overall['Accuracy'],
glm_results$confusion_matrix$overall['Accuracy'],
lda_results$confusion_matrix$overall['Accuracy']),
Kappa = c(rf_results$confusion_matrix$overall['Kappa'],
svm_results$confusion_matrix$overall['Kappa'],
knn_results$confusion_matrix$overall['Kappa'],
gbm_results$confusion_matrix$overall['Kappa'],
glm_results$confusion_matrix$overall['Kappa'],
lda_results$confusion_matrix$overall['Kappa'])
)
print(results)
confusionMatrix(p1, tst$smoking)
View(samplekey)
print(model_rf)
confusionMatrix(pr_class, test_transposed$smoking)
print(conf_matrix)
confusionMatrix(pr, test_transposed$ smoking)
model_rf <- randomForest(smoking ~ ., data = train_transposed, proximity=TRUE)
confusionMatrix(pr, test_transposed$ smoking)
pr <- predict(model_rf, test_transposed)
confusionMatrix(pr, test_transposed$ smoking)
print(model_rf)
library(pROC)
predicted_probs <- predict(model_rf, test_transposed, type = "prob")
# Построение кривой Precision-Recall
pr_curve <- roc(test_transposed$smoking, predicted_probs[, "smoker"])
View(predicted_probs)
pr_curve_data <- coords(pr_curve, x = "all", input = "threshold", transpose = FALSE)
plot(pr_curve_data$specificity, pr_curve_data$sensitivity, type = "l", col = "blue",
xlab = "1 - Specificity", ylab = "Sensitivity", main = "Precision-Recall Curve")
plot(pr_curve_data$recall, pr_curve_data$precision, type = "l", col = "blue",
xlab = "Recall", ylab = "Precision", main = "Precision-Recall Curve")
table(pc_curve_data)
table(pr_curve_data)
View(pr_curve_data)
plot(model_rf)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
### Validation #################################################################
train_control <- trainControl(method = "cv", number = 10)
model_rf <- randomForest(smoking ~ ., data = train_transposed,ntree = 1000, proximity=TRUE)
print(model_rf)
test_transposed <- as.data.frame(t(test))
test_donors <- row.names(test_transposed)
test_transposed$smoking <- samplekey[test_donors,]$smoking
test_transposed$smoking <- as.factor(test_transposed$smoking)
pr <- predict(model_rf, test_transposed)
confusionMatrix(pr, test_transposed$ smoking)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
plot(train_control$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(train_control$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate / Accuracy', main='Error Rate and Accuracy by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
lines(accuracy, type='l', col='green') # Добавляем линию для точности
# Добавляем легенду
legend('topright', legend=c('Training', 'Out-of-Bag', 'Accuracy'), col=c('blue', 'red', 'green'), lty=1, y = 0)
accuracy <- 1 - model_rf$err.rate[,1]
lines(accuracy, type='l', col='green')
plot
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate / Accuracy', main='Error Rate and Accuracy by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
accuracy <- 1 - model_rf$err.rate[,1]
lines(accuracy, type='l', col='green')
# Добавляем легенду
legend('topright', legend=c('Training', 'Out-of-Bag', 'Accuracy'), col=c('blue', 'red', 'green'), lty=1, y = 0)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate / Accuracy', main='Error Rate and Accuracy by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
# Вычисляем и добавляем линию для точности
accuracy <- 1 - model_rf$err.rate[,1]
lines(accuracy, type='l', col='green')
# Добавляем легенду
legend('topright', legend=c('Training', 'Out-of-Bag', 'Accuracy'), col=c('blue', 'red', 'green'), lty=1, y = 0)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
### Validation #################################################################
train_control <- trainControl(method = "cv", number = 10)
accuracy <- 1 - model_rf$err.rate[,1]
lines(accuracy, type='l', col='green')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
View(model_rf)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
### Validation #################################################################
train_control <- trainControl(method = "cv", number = 10)
print(model_rf)
confusionMatrix(pr, test_transposed$ smoking)
pr <- predict(model_rf, test_transposed)
confusionMatrix(pr, test_transposed$ smoking)
source("C:/Users/Wolchear/Desktop/bio4/4uzd.R")
print(classification_model)
model_rf <- randomForest(smoking ~ ., data = train_transposed,ntree = 2, proximity=TRUE)
print(model_rf)
model_rf <- randomForest(smoking ~ ., data = train_transposed,ntree = 1000, proximity=TRUE)
print(model_rf)
confusionMatrix(pr_class, test_transposed$smoking)
print
print(classification_model)
confusionMatrix(pr_class, test_transposed$smoking)
print(classification_model)
print(results)
confusionMatrix(p1, tst$smoking)
confusionMatrix(p, trg$smoking)
p1 <- predict(pca_model, tst)
confusionMatrix(p1, tst$smoking)
p1 <- predict(pca_model, tst)
pca_model <- multinom(smoking~., data = trg)
summary(pca_model)
p <- predict(pca_model, trg)
confusionMatrix(p, trg$smoking)
p1 <- predict(pca_model, tst)
confusionMatrix(p1, tst$smoking)
print(pca_model)
conf_train <- confusionMatrix(p, trg$smoking)$table
error_rate_train <- diag(conf_train) / rowSums(conf_train)
# Для тестового набора данных
conf_test <- confusionMatrix(p1, tst$smoking)$table
error_rate_test <- diag(conf_test) / rowSums(conf_test)
# Вывод ошибки классификации для каждого класса
cat("Error Rate for each class on Training data:", error_rate_train, "\n")
cat("Error Rate for each class on Test data:", error_rate_test, "\n")
print(model_gbm)
model_gbm_predict <- predict(model_gbm, newdata = test_transposed)
confusionMatrix(model_gbm_predict, test_transposed$smoking)
View(model_gbm)
# Вывод ошибки классификации для каждого класса
cat("Error Rate for each class on Test data:", error_rate_test, "\n")
confusionMatrix(p1, tst$smoking)
View(pca_model)
confusionMatrix(p1, tst$smoking)
data <- readRDS("data2.rds")
genomemap <- readRDS("genomemap2.rds")
samplekey <- readRDS("samplekey2.rds")
library(randomForest)
library(datasets)
library(caret)
library(nnet)
library(pROC)
library(e1071)  # For SVM
library(class)  # For KNN
library(gbm)    # For GBM
library(MASS)   # For LDA
### Random Forest Classification ##############################################
set.seed(123)
data_variable <- data[order(apply(data, 1, sd),
decreasing = TRUE),][1:1000, ]
ind <- sample(2, ncol(data_variable), replace = TRUE, prob = c(0.8, 0.2))
train <- data_variable[,ind==1]
test <- data_variable[,ind==2]
train_transposed <- as.data.frame(t(train))
train_donors <- row.names(train_transposed)
train_transposed$smoking <- samplekey[train_donors,]$smoking
train_transposed$smoking <- as.factor(train_transposed$smoking)
model_rf <- randomForest(smoking ~ ., data = train_transposed,ntree = 1000, proximity=TRUE)
print(model_rf)
test_transposed <- as.data.frame(t(test))
test_donors <- row.names(test_transposed)
test_transposed$smoking <- samplekey[test_donors,]$smoking
test_transposed$smoking <- as.factor(test_transposed$smoking)
pr <- predict(model_rf, test_transposed)
confusionMatrix(pr, test_transposed$ smoking)
plot(model_rf$err.rate[,1], type='l', col='blue', ylim=c(0,0.5),
ylab='Error Rate', main='Error Rate by Number of Trees', xlab='Number of Trees')
lines(model_rf$err.rate[,2], type='l', col='red')
legend('topright', legend=c('Training', 'Out-of-Bag'), col=c('blue', 'red'), lty=1, y = 0)
### Validation #################################################################
train_control <- trainControl(method = "cv", number = 10)
classification_model <- train(smoking ~ ., data = train_transposed,
method = "rf", trControl = train_control)
print(classification_model)
pr_class <- predict(classification_model, newdata = test_transposed)
confusionMatrix(pr_class, test_transposed$smoking)
####################
# Function to evaluate classifiers
evaluate_classifier <- function(model, test_data, test_labels) {
predictions <- predict(model, newdata = test_data)
conf_matrix <- confusionMatrix(predictions, test_labels)
return(list(predictions = predictions, confusion_matrix = conf_matrix))
}
# Train and evaluate Random Forest
model_rf <- train(smoking ~ ., data = train_transposed,
method = "rf", trControl = train_control)
rf_results <- evaluate_classifier(model_rf,
test_transposed, test_transposed$smoking)
# Train and evaluate SVM
model_svm <- train(smoking ~ ., data = train_transposed,
method = "svmRadial", trControl = train_control)
svm_results <- evaluate_classifier(model_svm,
test_transposed, test_transposed$smoking)
# Train and evaluate KNN
model_knn <- train(smoking ~ ., data = train_transposed, method = "knn",
trControl = train_control, tuneLength = 10)
knn_results <- evaluate_classifier(model_knn,
test_transposed, test_transposed$smoking)
# Train and evaluate GBM
model_gbm <- train(smoking ~ ., data = train_transposed, method = "gbm",
trControl = train_control, verbose = FALSE)
model_gbm_predict <- predict(model_gbm, newdata = test_transposed)
confusionMatrix(model_gbm_predict, test_transposed$smoking)
gbm_results <- evaluate_classifier(model_gbm,
test_transposed, test_transposed$smoking)
# Train and evaluate Logistic Regression
model_glm <- train(smoking ~ ., data = train_transposed, method = "glm",
family = binomial, trControl = train_control)
glm_results <- evaluate_classifier(model_glm, test_transposed,
test_transposed$smoking)
# Train and evaluate Linear Discriminant Analysis (LDA)
model_lda <- train(smoking ~ ., data = train_transposed,
method = "lda", trControl = train_control)
lda_results <- evaluate_classifier(model_lda,
test_transposed, test_transposed$smoking)
results <- data.frame(
Model = c("Random Forest", "SVM", "KNN", "GBM", "Logistic Regression", "LDA"),
Accuracy = c(rf_results$confusion_matrix$overall['Accuracy'],
svm_results$confusion_matrix$overall['Accuracy'],
knn_results$confusion_matrix$overall['Accuracy'],
gbm_results$confusion_matrix$overall['Accuracy'],
glm_results$confusion_matrix$overall['Accuracy'],
lda_results$confusion_matrix$overall['Accuracy']),
Kappa = c(rf_results$confusion_matrix$overall['Kappa'],
svm_results$confusion_matrix$overall['Kappa'],
knn_results$confusion_matrix$overall['Kappa'],
gbm_results$confusion_matrix$overall['Kappa'],
glm_results$confusion_matrix$overall['Kappa'],
lda_results$confusion_matrix$overall['Kappa'])
)
print(results)
### Principine komponente ######################################################
pc <- prcomp(train_transposed[,-1001],
center = TRUE,
scale. = TRUE)
trg <- predict(pc, train_transposed)
trg <- data.frame(trg, train_transposed[1001])
tst <- predict(pc, test_transposed)
tst <- data.frame(tst, test_transposed[1001])
pca_model <- multinom(smoking~., data = trg)
print(pca_model)
p <- predict(pca_model, trg)
confusionMatrix(p, trg$smoking)
p1 <- predict(pca_model, tst)
confusionMatrix(p1, tst$smoking)
